{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create our baseline linear model. It will not contain time-dependent exogenous variables. What is more we will not focus on econometrics - BLUE assumptions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import (\n",
    "    mutual_info_classif,\n",
    "    f_classif,\n",
    "\n",
    ")  # \n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# np.random.seed(1916) #uncomment if you want your code to be reproducible; for the purposes of our activity, let's add some randomness to the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\finance quantitative\\\\Third Semester'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_output_data_path = \"data\"\n",
    "\n",
    "df = pd.read_csv(f\"{preprocessed_output_data_path}/train_fe.csv\", index_col=0)\n",
    "df_test = pd.read_csv(f\"{preprocessed_output_data_path}/test_fe.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Variable Transformation:\n",
    "\n",
    "Low Tax Avoidance (Class 0): ETR > 0.25 (companies paying relatively high taxes)\n",
    "\n",
    "Medium Tax Avoidance (Class 1): 0.15 < ETR ≤ 0.25\n",
    "\n",
    "High Tax Avoidance (Class 2): ETR ≤ 0.15 (companies with aggressive tax optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etr_category\n",
      "1    1668\n",
      "0    1267\n",
      "2    1058\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "conditions = [\n",
    "    df[\"etr\"] > 0.25,\n",
    "    (df[\"etr\"] >= 0.15) & (df[\"etr\"] <= 0.25),\n",
    "    df[\"etr\"] <= 0.15,\n",
    "]\n",
    "\n",
    "labels = [0, 1, 2]\n",
    "df[\"etr_category\"] = np.select(conditions, labels)\n",
    "print(df[\"etr_category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etr_category\n",
      "1    195\n",
      "0    103\n",
      "2     65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test[\"etr_category\"] = np.select(conditions, labels)\n",
    "print(df_test[\"etr_category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.Figure(figsize=(10, 6))\n",
    "sns.countplot(x=\"etr_category\", data=df)\n",
    "plt.title(\"Distribution of ETR Categories\")\n",
    "plt.xlabel(\"ETR Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = df.columns.drop([\"etr\", \"etr_category\",\"Ticker\",\"Nazwa2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rok': 0, 'ta': 0.13613770002088987, 'txt': 0.17189627762095983, 'pi': 0.1648469491590736, 'str': 0.13411116074284424, 'xrd': 0.059546147219663004, 'ni': 0.1662938495322317, 'ppent': 0.10080982233343372, 'intant': 0.16867913200704976, 'dlc': 0.12228922975167578, 'dltt': 0.0958388065206166, 'capex': 0.1286078793953025, 'revenue': 0.13848124983854992, 'cce': 0.12274488625119817, 'adv': 0.002384054750034892, 'diff': 0.1664422646980992, 'roa': 0.13080944332621813, 'lev': 0.08834712676267142, 'intan': 0.10983468554856879, 'rd': 0.04929763857258451, 'ppe': 0.10313529451901982, 'sale': 0.10428856063851266, 'cash_holdings': 0.08630100298970556, 'adv_expenditure': 0, 'capex2': 0.08509224434724971, 'cfc': 0.08505855621975567, 'dta': 0.04771866847874007, 'capex2_scaled': 0.09417036745052476, 'y_v2x_polyarchy': 0.07705254665347838, 'y_e_p_polity': 0.029086067476211896, 'y_BR_Democracy': 0, 'WB_GDPgrowth': 0.11091653071327667, 'WB_GDPpc': 0.10806835027013428, 'WB_Inflation': 0.11210544533561717, 'rr_per_country': 0.0927838112117958, 'rr_per_sector': 0.008760595033494356, 'sektor_consumer discretionary': 0.0045696279103144555, 'sektor_consumer staples': 0, 'sektor_energy': 0.0062250230394858, 'sektor_health care': 0.006139611713745108, 'sektor_industrials': 0.019889955988286356, 'sektor_materials': 0.0017041399239605681, 'sektor_real estate': 0.0027749060041406537, 'sektor_technology': 0, 'sektor_utilities': 0.0013891778541283983, 'gielda_2': 0.043107275650883015, 'gielda_3': 0.0028647787479920694, 'gielda_4': 0.035456800510124564, 'gielda_5': 0, 'ta_log': 0.13557490427775587, 'txt_cat_(-63.011, -34.811]': 0.000495686659963912, 'txt_cat_(-34.811, 0.488]': 0.033408141135998326, 'txt_cat_(0.488, 24.415]': 0.04974157806921675, 'txt_cat_(24.415, 25.05]': 0, 'txt_cat_(25.05, 308.55]': 0.028785272459018962, 'txt_cat_(308.55, 327.531]': 0.0057451070657896786, 'txt_cat_(327.531, inf]': 0.030238055255190188, 'pi_cat_(-8975.0, -1.523]': 0.029738814747528153, 'pi_cat_(-1.523, 157.119]': 0.05127710557438414, 'pi_cat_(157.119, 465.9]': 0.005465888464081248, 'pi_cat_(465.9, 7875.5]': 0.033061896920656864, 'pi_cat_(7875.5, 8108.5]': 0, 'pi_cat_(8108.5, inf]': 0.006972933811481896, 'str_cat_(0.0875, 0.192]': 0.10043973561478525, 'str_cat_(0.192, 0.28]': 0, 'str_cat_(0.28, inf]': 0.060871779534534376, 'xrd_exists': 0.05106774966283778, 'ni_profit': 0.024263812076220193, 'ni_profit_20000': 0, 'ppent_sqrt': 0.10500034948999248, 'intant_sqrt': 0.16230528657199028, 'dlc_cat_(42.262, 176.129]': 0.007854056371419338, 'dlc_cat_(176.129, 200.9]': 0, 'dlc_cat_(200.9, inf]': 0.06306873535432311, 'dltt_cat_(39.38, 327.85]': 0, 'dltt_cat_(327.85, 876.617]': 0.015202019907687436, 'dltt_cat_(876.617, inf]': 0.024096906364545978, 'capex_cat_(7.447, 79.55]': 0, 'capex_cat_(79.55, 5451.0]': 0.01628459606269317, 'capex_cat_(5451.0, inf]': 0.011544714123013833, 'revenue_cat_(0.174, 1248.817]': 0.053396161355553584, 'revenue_cat_(1248.817, 4233.587]': 0.0033840112235021813, 'revenue_cat_(4233.587, inf]': 0.054534204262207675, 'cce_cat_(5.619, 63.321]': 0.026994003019542356, 'cce_cat_(63.321, inf]': 0.06343329271317244, 'adv_cat_(0.3, 874.5]': 0, 'adv_cat_(874.5, inf]': 0, 'diff_positive': 0.03102545083959174, 'roa_clip': 0.13255343353367421, 'lev_sqrt': 0.08779454693478983, 'intan_pow2': 0.10732178973728601, 'rd_sqrt': 0.043668140625537255, 'ppe_clip': 0.1053173762898032, 'cash_holdings_sqrt': 0.08655948662339563, 'adv_expenditure_positive': 0.00534445583490184, 'diff_dta': 0.023531450211083715, 'cfc_dta': 0.029182432774960354, 'etr_y_past': 0.29019008907030663, 'etr_y_ma': 0.2859653082868687, 'diff_ma': 0.1785137839470745, 'roa_ma': 0.12494810329107353, 'lev_ma': 0.12705434257855486, 'intan_ma': 0.16648550998659162, 'ppe_ma': 0.13896672887939743, 'sale_ma': 0.14239301140164962, 'cash_holdings_ma': 0.138501465061466, 'roa_past': 0.12707266964400432, 'lev_past': 0.10924372917646497, 'intan_past': 0.12246096147213392, 'ppe_past': 0.13433500964416933, 'sale_past': 0.11847819027260487, 'cash_holdings_past': 0.12813740932675355}\n"
     ]
    }
   ],
   "source": [
    "mutul_info_dict = dict()\n",
    "for col in x_col:\n",
    "    mutul_info_dict[col] = mutual_info_classif(\n",
    "        df[[col]],\n",
    "        df[\"etr_category\"],\n",
    "    )[0]\n",
    "print(mutul_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rok</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ta</th>\n",
       "      <td>0.136138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>0.171896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pi</th>\n",
       "      <td>0.164847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str</th>\n",
       "      <td>0.134111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lev_past</th>\n",
       "      <td>0.109244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intan_past</th>\n",
       "      <td>0.122461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppe_past</th>\n",
       "      <td>0.134335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_past</th>\n",
       "      <td>0.118478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_holdings_past</th>\n",
       "      <td>0.128137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mutual_info\n",
       "rok                    0.000000\n",
       "ta                     0.136138\n",
       "txt                    0.171896\n",
       "pi                     0.164847\n",
       "str                    0.134111\n",
       "...                         ...\n",
       "lev_past               0.109244\n",
       "intan_past             0.122461\n",
       "ppe_past               0.134335\n",
       "sale_past              0.118478\n",
       "cash_holdings_past     0.128137\n",
       "\n",
       "[112 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr = pd.DataFrame.from_dict(mutul_info_dict, orient=\"index\", columns=[\"mutual_info\"])\n",
    "fr  #larger value means more important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate THREE classification models:\n",
    "\n",
    "Logistic Regression (multiclass)\n",
    "\n",
    "K-Nearest Neighbors Classifier\n",
    "\n",
    "Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logitic Regression multiclass\n",
    "I want to compare the top 10, top 20, top 30... top all features, selcect how many features can be the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt']\n",
      "Top 20 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa']\n",
      "Top 30 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation']\n",
      "Top 40 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation', 'WB_GDPgrowth', 'intan', 'lev_past', 'WB_GDPpc', 'intan_pow2', 'ppe_clip', 'ppent_sqrt', 'sale', 'ppe', 'ppent']\n",
      "Top 50 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation', 'WB_GDPgrowth', 'intan', 'lev_past', 'WB_GDPpc', 'intan_pow2', 'ppe_clip', 'ppent_sqrt', 'sale', 'ppe', 'ppent', 'str_cat_(0.0875, 0.192]', 'dltt', 'capex2_scaled', 'rr_per_country', 'lev', 'lev_sqrt', 'cash_holdings_sqrt', 'cash_holdings', 'capex2', 'cfc']\n",
      "Top 60 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation', 'WB_GDPgrowth', 'intan', 'lev_past', 'WB_GDPpc', 'intan_pow2', 'ppe_clip', 'ppent_sqrt', 'sale', 'ppe', 'ppent', 'str_cat_(0.0875, 0.192]', 'dltt', 'capex2_scaled', 'rr_per_country', 'lev', 'lev_sqrt', 'cash_holdings_sqrt', 'cash_holdings', 'capex2', 'cfc', 'y_v2x_polyarchy', 'cce_cat_(63.321, inf]', 'dlc_cat_(200.9, inf]', 'str_cat_(0.28, inf]', 'xrd', 'revenue_cat_(4233.587, inf]', 'revenue_cat_(0.174, 1248.817]', 'pi_cat_(-1.523, 157.119]', 'xrd_exists', 'txt_cat_(0.488, 24.415]']\n",
      "Top 70 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation', 'WB_GDPgrowth', 'intan', 'lev_past', 'WB_GDPpc', 'intan_pow2', 'ppe_clip', 'ppent_sqrt', 'sale', 'ppe', 'ppent', 'str_cat_(0.0875, 0.192]', 'dltt', 'capex2_scaled', 'rr_per_country', 'lev', 'lev_sqrt', 'cash_holdings_sqrt', 'cash_holdings', 'capex2', 'cfc', 'y_v2x_polyarchy', 'cce_cat_(63.321, inf]', 'dlc_cat_(200.9, inf]', 'str_cat_(0.28, inf]', 'xrd', 'revenue_cat_(4233.587, inf]', 'revenue_cat_(0.174, 1248.817]', 'pi_cat_(-1.523, 157.119]', 'xrd_exists', 'txt_cat_(0.488, 24.415]', 'rd', 'dta', 'rd_sqrt', 'gielda_2', 'gielda_4', 'txt_cat_(-34.811, 0.488]', 'pi_cat_(465.9, 7875.5]', 'diff_positive', 'txt_cat_(327.531, inf]', 'pi_cat_(-8975.0, -1.523]']\n",
      "Top 80 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation', 'WB_GDPgrowth', 'intan', 'lev_past', 'WB_GDPpc', 'intan_pow2', 'ppe_clip', 'ppent_sqrt', 'sale', 'ppe', 'ppent', 'str_cat_(0.0875, 0.192]', 'dltt', 'capex2_scaled', 'rr_per_country', 'lev', 'lev_sqrt', 'cash_holdings_sqrt', 'cash_holdings', 'capex2', 'cfc', 'y_v2x_polyarchy', 'cce_cat_(63.321, inf]', 'dlc_cat_(200.9, inf]', 'str_cat_(0.28, inf]', 'xrd', 'revenue_cat_(4233.587, inf]', 'revenue_cat_(0.174, 1248.817]', 'pi_cat_(-1.523, 157.119]', 'xrd_exists', 'txt_cat_(0.488, 24.415]', 'rd', 'dta', 'rd_sqrt', 'gielda_2', 'gielda_4', 'txt_cat_(-34.811, 0.488]', 'pi_cat_(465.9, 7875.5]', 'diff_positive', 'txt_cat_(327.531, inf]', 'pi_cat_(-8975.0, -1.523]', 'cfc_dta', 'y_e_p_polity', 'txt_cat_(25.05, 308.55]', 'cce_cat_(5.619, 63.321]', 'ni_profit', 'dltt_cat_(876.617, inf]', 'diff_dta', 'sektor_industrials', 'capex_cat_(79.55, 5451.0]', 'dltt_cat_(327.85, 876.617]']\n",
      "Top 90 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation', 'WB_GDPgrowth', 'intan', 'lev_past', 'WB_GDPpc', 'intan_pow2', 'ppe_clip', 'ppent_sqrt', 'sale', 'ppe', 'ppent', 'str_cat_(0.0875, 0.192]', 'dltt', 'capex2_scaled', 'rr_per_country', 'lev', 'lev_sqrt', 'cash_holdings_sqrt', 'cash_holdings', 'capex2', 'cfc', 'y_v2x_polyarchy', 'cce_cat_(63.321, inf]', 'dlc_cat_(200.9, inf]', 'str_cat_(0.28, inf]', 'xrd', 'revenue_cat_(4233.587, inf]', 'revenue_cat_(0.174, 1248.817]', 'pi_cat_(-1.523, 157.119]', 'xrd_exists', 'txt_cat_(0.488, 24.415]', 'rd', 'dta', 'rd_sqrt', 'gielda_2', 'gielda_4', 'txt_cat_(-34.811, 0.488]', 'pi_cat_(465.9, 7875.5]', 'diff_positive', 'txt_cat_(327.531, inf]', 'pi_cat_(-8975.0, -1.523]', 'cfc_dta', 'y_e_p_polity', 'txt_cat_(25.05, 308.55]', 'cce_cat_(5.619, 63.321]', 'ni_profit', 'dltt_cat_(876.617, inf]', 'diff_dta', 'sektor_industrials', 'capex_cat_(79.55, 5451.0]', 'dltt_cat_(327.85, 876.617]', 'capex_cat_(5451.0, inf]', 'rr_per_sector', 'dlc_cat_(42.262, 176.129]', 'pi_cat_(8108.5, inf]', 'sektor_energy', 'sektor_health care', 'txt_cat_(308.55, 327.531]', 'pi_cat_(157.119, 465.9]', 'adv_expenditure_positive', 'sektor_consumer discretionary']\n",
      "Top 100 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation', 'WB_GDPgrowth', 'intan', 'lev_past', 'WB_GDPpc', 'intan_pow2', 'ppe_clip', 'ppent_sqrt', 'sale', 'ppe', 'ppent', 'str_cat_(0.0875, 0.192]', 'dltt', 'capex2_scaled', 'rr_per_country', 'lev', 'lev_sqrt', 'cash_holdings_sqrt', 'cash_holdings', 'capex2', 'cfc', 'y_v2x_polyarchy', 'cce_cat_(63.321, inf]', 'dlc_cat_(200.9, inf]', 'str_cat_(0.28, inf]', 'xrd', 'revenue_cat_(4233.587, inf]', 'revenue_cat_(0.174, 1248.817]', 'pi_cat_(-1.523, 157.119]', 'xrd_exists', 'txt_cat_(0.488, 24.415]', 'rd', 'dta', 'rd_sqrt', 'gielda_2', 'gielda_4', 'txt_cat_(-34.811, 0.488]', 'pi_cat_(465.9, 7875.5]', 'diff_positive', 'txt_cat_(327.531, inf]', 'pi_cat_(-8975.0, -1.523]', 'cfc_dta', 'y_e_p_polity', 'txt_cat_(25.05, 308.55]', 'cce_cat_(5.619, 63.321]', 'ni_profit', 'dltt_cat_(876.617, inf]', 'diff_dta', 'sektor_industrials', 'capex_cat_(79.55, 5451.0]', 'dltt_cat_(327.85, 876.617]', 'capex_cat_(5451.0, inf]', 'rr_per_sector', 'dlc_cat_(42.262, 176.129]', 'pi_cat_(8108.5, inf]', 'sektor_energy', 'sektor_health care', 'txt_cat_(308.55, 327.531]', 'pi_cat_(157.119, 465.9]', 'adv_expenditure_positive', 'sektor_consumer discretionary', 'revenue_cat_(1248.817, 4233.587]', 'gielda_3', 'sektor_real estate', 'adv', 'sektor_materials', 'sektor_utilities', 'txt_cat_(-63.011, -34.811]', 'sektor_consumer staples', 'y_BR_Democracy', 'adv_expenditure']\n",
      "Top 110 features: ['etr_y_past', 'etr_y_ma', 'diff_ma', 'txt', 'intant', 'intan_ma', 'diff', 'ni', 'pi', 'intant_sqrt', 'sale_ma', 'ppe_ma', 'cash_holdings_ma', 'revenue', 'ta', 'ta_log', 'ppe_past', 'str', 'roa_clip', 'roa', 'capex', 'cash_holdings_past', 'roa_past', 'lev_ma', 'roa_ma', 'cce', 'intan_past', 'dlc', 'sale_past', 'WB_Inflation', 'WB_GDPgrowth', 'intan', 'lev_past', 'WB_GDPpc', 'intan_pow2', 'ppe_clip', 'ppent_sqrt', 'sale', 'ppe', 'ppent', 'str_cat_(0.0875, 0.192]', 'dltt', 'capex2_scaled', 'rr_per_country', 'lev', 'lev_sqrt', 'cash_holdings_sqrt', 'cash_holdings', 'capex2', 'cfc', 'y_v2x_polyarchy', 'cce_cat_(63.321, inf]', 'dlc_cat_(200.9, inf]', 'str_cat_(0.28, inf]', 'xrd', 'revenue_cat_(4233.587, inf]', 'revenue_cat_(0.174, 1248.817]', 'pi_cat_(-1.523, 157.119]', 'xrd_exists', 'txt_cat_(0.488, 24.415]', 'rd', 'dta', 'rd_sqrt', 'gielda_2', 'gielda_4', 'txt_cat_(-34.811, 0.488]', 'pi_cat_(465.9, 7875.5]', 'diff_positive', 'txt_cat_(327.531, inf]', 'pi_cat_(-8975.0, -1.523]', 'cfc_dta', 'y_e_p_polity', 'txt_cat_(25.05, 308.55]', 'cce_cat_(5.619, 63.321]', 'ni_profit', 'dltt_cat_(876.617, inf]', 'diff_dta', 'sektor_industrials', 'capex_cat_(79.55, 5451.0]', 'dltt_cat_(327.85, 876.617]', 'capex_cat_(5451.0, inf]', 'rr_per_sector', 'dlc_cat_(42.262, 176.129]', 'pi_cat_(8108.5, inf]', 'sektor_energy', 'sektor_health care', 'txt_cat_(308.55, 327.531]', 'pi_cat_(157.119, 465.9]', 'adv_expenditure_positive', 'sektor_consumer discretionary', 'revenue_cat_(1248.817, 4233.587]', 'gielda_3', 'sektor_real estate', 'adv', 'sektor_materials', 'sektor_utilities', 'txt_cat_(-63.011, -34.811]', 'sektor_consumer staples', 'y_BR_Democracy', 'adv_expenditure', 'ni_profit_20000', 'txt_cat_(24.415, 25.05]', 'sektor_technology', 'gielda_5', 'adv_cat_(874.5, inf]', 'adv_cat_(0.3, 874.5]', 'pi_cat_(7875.5, 8108.5]', 'capex_cat_(7.447, 79.55]', 'dltt_cat_(39.38, 327.85]', 'str_cat_(0.192, 0.28]']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in np.arange(10, len(x_col)+1, 10):\n",
    "    print(f\"Top {i} features:\", fr.sort_values(by=\"mutual_info\", ascending=False).head(i).index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with top 10 features...\n",
      "Best parameters for top 10 features: {'C': 10, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 10 features: 0.5930827067669173\n",
      "Training model with top 20 features...\n",
      "Best parameters for top 20 features: {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 20 features: 0.4893233082706767\n",
      "Training model with top 30 features...\n",
      "Best parameters for top 30 features: {'C': 1, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 30 features: 0.49744360902255635\n",
      "Training model with top 40 features...\n",
      "Best parameters for top 40 features: {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 40 features: 0.5028571428571429\n",
      "Training model with top 50 features...\n",
      "Best parameters for top 50 features: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 50 features: 0.5013533834586467\n",
      "Training model with top 60 features...\n",
      "Best parameters for top 60 features: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 60 features: 0.4947368421052631\n",
      "Training model with top 70 features...\n",
      "Best parameters for top 70 features: {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 70 features: 0.5004511278195488\n",
      "Training model with top 80 features...\n",
      "Best parameters for top 80 features: {'C': 10, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 80 features: 0.5193984962406015\n",
      "Training model with top 90 features...\n",
      "Best parameters for top 90 features: {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 90 features: 0.5190977443609023\n",
      "Training model with top 100 features...\n",
      "Best parameters for top 100 features: {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 100 features: 0.5142857142857143\n",
      "Training model with top 110 features...\n",
      "Best parameters for top 110 features: {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best cross-validation score for top 110 features: 0.5181954887218045\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "log_classifier = LogisticRegression(max_iter=1000)\n",
    "parameter_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs',\"sage\"],\n",
    "    'multi_class': ['ovr','multinomial'],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "# Suppose you want 5 splits\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "results = dict()\n",
    "for i in np.arange(10, len(x_col)+1, 10):\n",
    "    print(f\"Training model with top {i} features...\")\n",
    "    clf = GridSearchCV(\n",
    "        log_classifier,\n",
    "        parameter_grid,\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        scoring=\"accuracy\",\n",
    "    )\n",
    "    selected_features = fr.sort_values(by=\"mutual_info\", ascending=False).head(i).index.tolist()\n",
    "    model = clf.fit(df[selected_features], df[\"etr_category\"])\n",
    "    results[i] = {\n",
    "        \"model\": model,\n",
    "        \"best_params\": clf.best_params_,\n",
    "        \"best_score\": clf.best_score_\n",
    "    }\n",
    "    \n",
    "    print(f\"Best parameters for top {i} features: {clf.best_params_}\")\n",
    "    print(f\"Best cross-validation score for top {i} features: {clf.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 10, 'multi_class': 'ovr', 'penalty': 'l2...</td>\n",
       "      <td>0.593083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...</td>\n",
       "      <td>0.489323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 1, 'multi_class': 'multinomial', 'penalt...</td>\n",
       "      <td>0.497444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...</td>\n",
       "      <td>0.502857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>0.501353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>0.494737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...</td>\n",
       "      <td>0.500451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 10, 'multi_class': 'ovr', 'penalty': 'l2...</td>\n",
       "      <td>0.519398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...</td>\n",
       "      <td>0.519098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...</td>\n",
       "      <td>{'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...</td>\n",
       "      <td>0.518195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model  \\\n",
       "10   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "20   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "30   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "40   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "50   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "60   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "70   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "80   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "90   GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "100  GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "110  GridSearchCV(cv=TimeSeriesSplit(gap=0, max_tra...   \n",
       "\n",
       "                                           best_params  best_score  \n",
       "10   {'C': 10, 'multi_class': 'ovr', 'penalty': 'l2...    0.593083  \n",
       "20   {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...    0.489323  \n",
       "30   {'C': 1, 'multi_class': 'multinomial', 'penalt...    0.497444  \n",
       "40   {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...    0.502857  \n",
       "50   {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...    0.501353  \n",
       "60   {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...    0.494737  \n",
       "70   {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...    0.500451  \n",
       "80   {'C': 10, 'multi_class': 'ovr', 'penalty': 'l2...    0.519398  \n",
       "90   {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...    0.519098  \n",
       "100  {'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'...    0.514286  \n",
       "110  {'C': 0.1, 'multi_class': 'ovr', 'penalty': 'l...    0.518195  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therefore, we can see that the top 10 features can give better scrore, then test to find whether align with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_classification_reports = {}\n",
    "for i in np.arange(10, len(x_col)+1, 10):\n",
    "    selected_features = fr.sort_values(by=\"mutual_info\", ascending=False).head(i).index.tolist()\n",
    "    params = results_df.loc[i, \"best_params\"]\n",
    "    \n",
    "    model = LogisticRegression(**params, max_iter=1000).fit(df[selected_features], df[\"etr_category\"])\n",
    "    pred = model.predict(df_test[selected_features])\n",
    "    \n",
    "    report_dict = classification_report(df_test[\"etr_category\"], pred, output_dict=True)\n",
    "    report_df = pd.DataFrame.from_dict(report_dict[\"macro avg\"], orient=\"index\").transpose()\n",
    "    Test_classification_reports[i] = report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>0</th>\n",
       "      <td>0.554321</td>\n",
       "      <td>0.538495</td>\n",
       "      <td>0.543291</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>0</th>\n",
       "      <td>0.356926</td>\n",
       "      <td>0.426587</td>\n",
       "      <td>0.387812</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>0</th>\n",
       "      <td>0.579763</td>\n",
       "      <td>0.448345</td>\n",
       "      <td>0.381323</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <th>0</th>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.424944</td>\n",
       "      <td>0.380921</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <th>0</th>\n",
       "      <td>0.501925</td>\n",
       "      <td>0.419998</td>\n",
       "      <td>0.386013</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <th>0</th>\n",
       "      <td>0.425400</td>\n",
       "      <td>0.409924</td>\n",
       "      <td>0.377201</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <th>0</th>\n",
       "      <td>0.371743</td>\n",
       "      <td>0.403269</td>\n",
       "      <td>0.367594</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <th>0</th>\n",
       "      <td>0.420170</td>\n",
       "      <td>0.424147</td>\n",
       "      <td>0.394670</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <th>0</th>\n",
       "      <td>0.426722</td>\n",
       "      <td>0.432329</td>\n",
       "      <td>0.401942</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <th>0</th>\n",
       "      <td>0.351292</td>\n",
       "      <td>0.428363</td>\n",
       "      <td>0.384708</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <th>0</th>\n",
       "      <td>0.357231</td>\n",
       "      <td>0.438072</td>\n",
       "      <td>0.391984</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score  support\n",
       "num_features                                          \n",
       "10           0   0.554321  0.538495  0.543291    363.0\n",
       "20           0   0.356926  0.426587  0.387812    363.0\n",
       "30           0   0.579763  0.448345  0.381323    363.0\n",
       "40           0   0.347222  0.424944  0.380921    363.0\n",
       "50           0   0.501925  0.419998  0.386013    363.0\n",
       "60           0   0.425400  0.409924  0.377201    363.0\n",
       "70           0   0.371743  0.403269  0.367594    363.0\n",
       "80           0   0.420170  0.424147  0.394670    363.0\n",
       "90           0   0.426722  0.432329  0.401942    363.0\n",
       "100          0   0.351292  0.428363  0.384708    363.0\n",
       "110          0   0.357231  0.438072  0.391984    363.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(Test_classification_reports, names=['num_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Still, the optimal model is 10 features, Now the baseline model with Macro F1 0.543, not quite good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. KNN classifer\n",
    "Due to KNN is more time consuming, and KNN may have the high-dimension issues. So just try 10, 20,30 feautures, and also the continuous features should do the standardsclaer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_features = fr.sort_values(by=\"mutual_info\", ascending=False).head(10).index.tolist()\n",
    "top_20_features = fr.sort_values(by=\"mutual_info\", ascending=False).head(20).index.tolist()\n",
    "top_30_features = fr.sort_values(by=\"mutual_info\", ascending=False).head(30).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3993 entries, 0 to 4354\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   etr_y_past          3993 non-null   float64\n",
      " 1   etr_y_ma            3993 non-null   float64\n",
      " 2   diff_ma             3993 non-null   float64\n",
      " 3   txt                 3993 non-null   float64\n",
      " 4   intant              3993 non-null   float64\n",
      " 5   intan_ma            3993 non-null   float64\n",
      " 6   diff                3993 non-null   float64\n",
      " 7   ni                  3993 non-null   float64\n",
      " 8   pi                  3993 non-null   float64\n",
      " 9   intant_sqrt         3993 non-null   float64\n",
      " 10  sale_ma             3993 non-null   float64\n",
      " 11  ppe_ma              3993 non-null   float64\n",
      " 12  cash_holdings_ma    3993 non-null   float64\n",
      " 13  revenue             3993 non-null   float64\n",
      " 14  ta                  3993 non-null   float64\n",
      " 15  ta_log              3993 non-null   float64\n",
      " 16  ppe_past            3993 non-null   float64\n",
      " 17  str                 3993 non-null   float64\n",
      " 18  roa_clip            3993 non-null   float64\n",
      " 19  roa                 3993 non-null   float64\n",
      " 20  capex               3993 non-null   float64\n",
      " 21  cash_holdings_past  3993 non-null   float64\n",
      " 22  roa_past            3993 non-null   float64\n",
      " 23  lev_ma              3993 non-null   float64\n",
      " 24  roa_ma              3993 non-null   float64\n",
      " 25  cce                 3993 non-null   float64\n",
      " 26  intan_past          3993 non-null   float64\n",
      " 27  dlc                 3993 non-null   float64\n",
      " 28  sale_past           3993 non-null   float64\n",
      " 29  WB_Inflation        3993 non-null   float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 967.1 KB\n"
     ]
    }
   ],
   "source": [
    "df[top_30_features].info() #all float\n",
    "scale_top10 = StandardScaler().fit(df[top_10_features])\n",
    "scale_top20 = StandardScaler().fit(df[top_20_features])\n",
    "scale_top30 = StandardScaler().fit(df[top_30_features])\n",
    "X_train_top10 = scale_top10.transform(df[top_10_features])\n",
    "X_train_top20 = scale_top20.transform(df[top_20_features])\n",
    "X_train_top30 = scale_top30.transform(df[top_30_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_top10 = scale_top10.transform(df_test[top_10_features])\n",
    "X_test_top20 = scale_top20.transform(df_test[top_20_features])\n",
    "X_test_top30 = scale_top30.transform(df_test[top_30_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for top 10 features: {'weights': 'uniform', 'n_neighbors': 9, 'metric': 'manhattan', 'algorithm': 'kd_tree'}\n",
      "Best parameters for top 20 features: {'weights': 'distance', 'n_neighbors': 9, 'metric': 'minkowski', 'algorithm': 'ball_tree'}\n",
      "Best parameters for top 30 features: {'weights': 'distance', 'n_neighbors': 9, 'metric': 'euclidean', 'algorithm': 'auto'}\n",
      "Best cross-validation score for top 10 features: 0.6266246497827614\n",
      "Best cross-validation score for top 20 features: 0.5646900644604316\n",
      "Best cross-validation score for top 30 features: 0.5444658645321276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# KNN pipeline\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameter_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "} # 4*2*4*3=96 combinations\n",
    "\n",
    "clf_top10 = RandomizedSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    parameter_grid,\n",
    "    n_iter=20,\n",
    "    cv=tscv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=1916\n",
    ")\n",
    "\n",
    "clf_top20 = RandomizedSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    parameter_grid,\n",
    "    n_iter=20,\n",
    "    cv=tscv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=1917  # optional: different random state\n",
    ")\n",
    "\n",
    "clf_top30 = RandomizedSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    parameter_grid,\n",
    "    n_iter=20,\n",
    "    cv=tscv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=1917  # optional: different random state\n",
    ")\n",
    "\n",
    "clf_top10.fit(X_train_top10, df[\"etr_category\"])\n",
    "clf_top20.fit(X_train_top20, df[\"etr_category\"])\n",
    "clf_top30.fit(X_train_top30, df[\"etr_category\"])\n",
    "\n",
    "print(\"Best parameters for top 10 features:\", clf_top10.best_params_)\n",
    "print(\"Best parameters for top 20 features:\", clf_top20.best_params_)\n",
    "print(\"Best parameters for top 30 features:\", clf_top30.best_params_)\n",
    "\n",
    "print(\"Best cross-validation score for top 10 features:\", clf_top10.best_score_)\n",
    "print(\"Best cross-validation score for top 20 features:\", clf_top20.best_score_)\n",
    "print(\"Best cross-validation score for top 30 features:\", clf_top30.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN has an significant imporement with 0.627 score,  and the still top 10 features has the best scores, then test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Top 10 Features Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59       103\n",
      "           1       0.72      0.64      0.67       195\n",
      "           2       0.45      0.54      0.49        65\n",
      "\n",
      "    accuracy                           0.61       363\n",
      "   macro avg       0.58      0.60      0.59       363\n",
      "weighted avg       0.63      0.61      0.62       363\n",
      "\n",
      "KNN Top 20 Features Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.57      0.59       103\n",
      "           1       0.72      0.64      0.68       195\n",
      "           2       0.37      0.52      0.44        65\n",
      "\n",
      "    accuracy                           0.60       363\n",
      "   macro avg       0.56      0.58      0.57       363\n",
      "weighted avg       0.62      0.60      0.61       363\n",
      "\n",
      "KNN Top 30 Features Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.60       103\n",
      "           1       0.73      0.69      0.71       195\n",
      "           2       0.43      0.51      0.47        65\n",
      "\n",
      "    accuracy                           0.63       363\n",
      "   macro avg       0.59      0.60      0.59       363\n",
      "weighted avg       0.64      0.63      0.63       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_top10 = KNeighborsClassifier(**clf_top10.best_params_).fit(X_train_top10, df[\"etr_category\"])\n",
    "knn_top20 = KNeighborsClassifier(**clf_top20.best_params_).fit(X_train_top20, df[\"etr_category\"])\n",
    "knn_top30 = KNeighborsClassifier(**clf_top30.best_params_).fit(X_train_top30, df[\"etr_category\"])\n",
    "\n",
    "knn_top10_predict = knn_top10.predict(X_test_top10)\n",
    "knn_top20_predict = knn_top20.predict(X_test_top20)\n",
    "knn_top30_predict = knn_top30.predict(X_test_top30)\n",
    "\n",
    "print(\"KNN Top 10 Features Classification Report:\\n\", classification_report(df_test[\"etr_category\"], knn_top10_predict))\n",
    "print(\"KNN Top 20 Features Classification Report:\\n\", classification_report(df_test[\"etr_category\"], knn_top20_predict))\n",
    "print(\"KNN Top 30 Features Classification Report:\\n\", classification_report(df_test[\"etr_category\"], knn_top30_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Therefore, KNN has the optimal macro F1 WITH 0.59, with top10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Vector support machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for top 10 features: {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Best parameters for top 20 features: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best parameters for top 30 features: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation score for top 10 features: 0.6343828228275804\n",
      "Best cross-validation score for top 20 features: 0.6145099409290814\n",
      "Best cross-validation score for top 30 features: 0.6074770162322892\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {\n",
    "    'C': [0.1, 1, 10],                 \n",
    "    'kernel': ['linear', 'rbf'],       \n",
    "    'gamma': ['scale', 0.1, 1],        \n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "clf_top10 = GridSearchCV(\n",
    "    SVC(),\n",
    "    parameter_grid,\n",
    "    cv=tscv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "clf_top20 = GridSearchCV(\n",
    "    SVC(),\n",
    "    parameter_grid,\n",
    "    cv=tscv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "clf_top30 = GridSearchCV(\n",
    "    SVC(),\n",
    "    parameter_grid,\n",
    "    cv=tscv,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "clf_top10.fit(X_train_top10, df[\"etr_category\"])\n",
    "clf_top20.fit(X_train_top20, df[\"etr_category\"])\n",
    "clf_top30.fit(X_train_top30, df[\"etr_category\"])\n",
    "\n",
    "print(\"Best parameters for top 10 features:\", clf_top10.best_params_)\n",
    "print(\"Best parameters for top 20 features:\", clf_top20.best_params_) \n",
    "print(\"Best parameters for top 30 features:\", clf_top30.best_params_)    \n",
    "\n",
    "print(\"Best cross-validation score for top 10 features:\", clf_top10.best_score_)\n",
    "print(\"Best cross-validation score for top 20 features:\", clf_top20.best_score_)\n",
    "print(\"Best cross-validation score for top 30 features:\", clf_top30.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Top 10 Features Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       103\n",
      "           1       0.74      0.69      0.71       195\n",
      "           2       0.44      0.54      0.49        65\n",
      "\n",
      "    accuracy                           0.64       363\n",
      "   macro avg       0.60      0.61      0.60       363\n",
      "weighted avg       0.65      0.64      0.64       363\n",
      "\n",
      "SVC Top 20 Features Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61       103\n",
      "           1       0.75      0.72      0.73       195\n",
      "           2       0.49      0.52      0.51        65\n",
      "\n",
      "    accuracy                           0.66       363\n",
      "   macro avg       0.61      0.62      0.62       363\n",
      "weighted avg       0.66      0.66      0.66       363\n",
      "\n",
      "SVC Top 30 Features Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       103\n",
      "           1       0.71      0.73      0.72       195\n",
      "           2       0.48      0.40      0.44        65\n",
      "\n",
      "    accuracy                           0.64       363\n",
      "   macro avg       0.59      0.58      0.59       363\n",
      "weighted avg       0.63      0.64      0.64       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVC_top10 = SVC(**clf_top10.best_params_).fit(X_train_top10, df[\"etr_category\"])\n",
    "SVC_top20 = SVC(**clf_top20.best_params_).fit(X_train_top20, df[\"etr_category\"])\n",
    "SVC_top30 = SVC(**clf_top30.best_params_).fit(X_train_top30, df[\"etr_category\"])\n",
    "\n",
    "SVC_top10_predict = SVC_top10.predict(X_test_top10)\n",
    "SVC_top20_predict = SVC_top20.predict(X_test_top20)\n",
    "SVC_top30_predict = SVC_top30.predict(X_test_top30)\n",
    "\n",
    "print(\"SVC Top 10 Features Classification Report:\\n\", classification_report(df_test[\"etr_category\"], SVC_top10_predict))\n",
    "print(\"SVC Top 20 Features Classification Report:\\n\", classification_report(df_test[\"etr_category\"], SVC_top20_predict))\n",
    "print(\"SVC Top 30 Features Classification Report:\\n\", classification_report(df_test[\"etr_category\"], SVC_top30_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Therefore, SVC has the optimal macro F1 WITH 0.62 in these 3 models（LM, KNN, SVC）with top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models saved successfully in 'models/' directory!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create a directory for models if it doesn't exist\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save best  SVC model for top 20 features\n",
    "with open(\"models/SVC_top20.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf_top20.best_estimator_, f)\n",
    "\n",
    "print(\"✅ Models saved successfully in 'models/' directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Therefore, when comparing different feature selection methods for relatively small datasets, feature selection plays a crucial role. Using too many features can easily lead to overfitting, especially in distance-based models or basic Linear Regression. Across the three models tested, the best performance was achieved when using around 10–20 top features, rather than including all 100+ features. This suggests that focusing on the most informative variables improves model accuracy and generalization.\n",
    "\n",
    "#### However, I wonder if this issue might be reduced when using decision tree–based algorithms. Models like Random Forest and XGBoost inherently include mechanisms such as feature subsampling and regularization that help control variance and prevent overfitting. Therefore, in these models, including a larger number of features might actually lead to better performance. Therefore, after this semester's learning, I'll try these models again in this prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bff0f7c864331389fa2ce0c5d534e26d0bfdbc8f9c927a5938dc8a191fde6d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
